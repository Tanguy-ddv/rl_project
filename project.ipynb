{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from session import Session\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "SOURCE_ENV = 'CustomHopper-source-v0'\n",
    "TARGET_ENV = 'CustomHopper-target-v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce with baseline agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the effect of the learning rate on the agent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/several_lr\"\n",
    "session =  Session(SOURCE_ENV, output_folder, 0, 'cpu')\n",
    "for lr in [1e-1, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4]:\n",
    "    for baseline in [0, 20, 50]:\n",
    "        session.load_reinforce_with_baseline(None, lr, baseline)\n",
    "        session.train_agent(n_episode=5000)\n",
    "session.store_infos(\"lr=[1e-1, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4], baselines = [0, 20, 50]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the role of the baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/several_baselines\"\n",
    "session = Session(SOURCE_ENV, output_folder, 1, 'cpu')\n",
    "for baseline in [0, 10, 20, 50, 100, 200, 500]:\n",
    "    session.load_reinforce_with_baseline(None, baseline=baseline)\n",
    "    session.train_agent(n_episode=10000)\n",
    "\n",
    "for baseline in [0, 10, 20, 50, 100, 200, 500]:\n",
    "    session.load_reinforce_with_baseline(None, baseline=baseline)\n",
    "    session.train_agent(n_episode=10000)\n",
    "\n",
    "session.store_infos(\"baselines = [0, 20, 50, 100, 200, 500, 0, 20, 50, 100, 200, 500]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can a moving baseline could improve the agent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/defined_moving_baseline\"\n",
    "session = Session(SOURCE_ENV, output_folder, 1, 'cpu')\n",
    "session.load_reinforce_with_baseline(None, baseline=0)\n",
    "session.train_agent_with_defined_moving_baseline(n_episodes_per_baseline=5000, baselines=[0, 10, 20, 50, 100, 200, 500])\n",
    "session.store_infos(\"baselines = [0, 20, 50, 100, 200, 500], 5000 ep per baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would a dynamic baseline help the agent reach a better reward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/increasing_goal_baseline2\"\n",
    "session = Session(SOURCE_ENV, output_folder, 0, 'cpu')\n",
    "session.load_reinforce_with_baseline(None, baseline=100)\n",
    "session.train_agent_with_increasing_goal_baseline(1500, 14, 0)\n",
    "session.store_infos(\"increasing baseline. 1500 ep/step, 14 steps, initial baseline=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a basic actor-critic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful creation of the session, first step is step=1.\n",
      "Action space: Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
      "State space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)\n",
      "Dynamics parameters: [2.53429174 3.92699082 2.71433605 5.0893801 ]\n",
      "Successful loading of the actor-critic agent.\n",
      "\u001b[1;32;40mEpisode: 3000 | Average return: 0.26 | Average episode length: 17.75\u001b[0m\n",
      "End of session step 1, Lasted 146.07 s, Best reward: 7.76\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"outputs/actorcritic_basic\"\n",
    "session = Session(SOURCE_ENV, output_folder, verbose=10)\n",
    "session.load_last_actor_critic()\n",
    "step = session.get_step()\n",
    "session.train_agent_with_checkpointing(150000, 1000, 50)\n",
    "session.store_infos(f\"Step {step}: Actor critic, 150k episodes, early stopping=1000\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
