{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from session import Session\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "SOURCE_ENV = 'CustomHopper-source-v0'\n",
    "TARGET_ENV = 'CustomHopper-target-v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce with baseline agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the effect of the learning rate on the agent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/several_lr\"\n",
    "session =  Session(SOURCE_ENV, output_folder, 0, 'cpu')\n",
    "for lr in [1e-1, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4]:\n",
    "    for baseline in [0, 20, 50]:\n",
    "        session.load_reinforce_with_baseline(None, lr, baseline)\n",
    "        session.train_agent(n_episode=5000)\n",
    "session.store_infos(\"lr=[1e-1, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4], baselines = [0, 20, 50]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the role of the baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/several_baselines\"\n",
    "session = Session(SOURCE_ENV, output_folder, 1, 'cpu')\n",
    "for baseline in [0, 10, 20, 50, 100, 200, 500]:\n",
    "    session.load_reinforce_with_baseline(None, baseline=baseline)\n",
    "    session.train_agent(n_episode=10000)\n",
    "\n",
    "for baseline in [0, 10, 20, 50, 100, 200, 500]:\n",
    "    session.load_reinforce_with_baseline(None, baseline=baseline)\n",
    "    session.train_agent(n_episode=10000)\n",
    "\n",
    "session.store_infos(\"baselines = [0, 20, 50, 100, 200, 500, 0, 20, 50, 100, 200, 500]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can a moving baseline could improve the agent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/defined_moving_baseline\"\n",
    "session = Session(SOURCE_ENV, output_folder, 1, 'cpu')\n",
    "session.load_reinforce_with_baseline(None, baseline=0)\n",
    "session.train_agent_with_defined_moving_baseline(n_episodes_per_baseline=5000, baselines=[0, 10, 20, 50, 100, 200, 500])\n",
    "session.store_infos(\"baselines = [0, 20, 50, 100, 200, 500], 5000 ep per baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would a dynamic baseline help the agent reach a better reward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"outputs/increasing_goal_baseline2\"\n",
    "session = Session(SOURCE_ENV, output_folder, 0, 'cpu')\n",
    "session.load_reinforce_with_baseline(None, baseline=100)\n",
    "session.train_agent_with_increasing_goal_baseline(1500, 14, 0)\n",
    "session.store_infos(\"increasing baseline. 1500 ep/step, 14 steps, initial baseline=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a basic actor-critic agent with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful creation of the session, first step is step=463.\n",
      "Action space: Box([-1. -1. -1.], [1. 1. 1.], (3,), float32)\n",
      "State space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf], (11,), float64)\n",
      "Dynamics parameters: [2.53429174 3.92699082 2.71433605 5.0893801 ]\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 463, Lasted 83.03 s, Best reward: 68.62\n",
      "Still 19798 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 464, Lasted 35.76 s, Best reward: 12.66\n",
      "Still 19791 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 465, Lasted 18.51 s, Best reward: 0.98\n",
      "Still 19776 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 466, Lasted 34.35 s, Best reward: 12.29\n",
      "Still 19720 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 467, Lasted 16.57 s, Best reward: 11.23\n",
      "Still 19673 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 468, Lasted 170.67 s, Best reward: 217.58\n",
      "Still 19472 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 469, Lasted 50.06 s, Best reward: 19.21\n",
      "Still 19261 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 470, Lasted 60.06 s, Best reward: 7.88\n",
      "Still 19001 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 382 | Average return: 7.12 | Average episode length: 12.42\u001b[0m\n",
      "End of session step 471, Lasted 77.75 s, Best reward: 16.01\n",
      "Still 18702 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 472, Lasted 42.62 s, Best reward: 5.32\n",
      "Still 18520 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 473, Lasted 30.00 s, Best reward: 6.15\n",
      "Still 18399 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 474, Lasted 120.33 s, Best reward: 116.69\n",
      "Still 18150 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 475, Lasted 28.60 s, Best reward: 11.39\n",
      "Still 18052 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 476, Lasted 17.83 s, Best reward: 7.90\n",
      "Still 18042 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 477, Lasted 16.43 s, Best reward: 50.84\n",
      "Still 18036 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 478, Lasted 31.84 s, Best reward: 41.92\n",
      "Still 17958 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 479, Lasted 17.58 s, Best reward: 34.69\n",
      "Still 17913 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 360 | Average return: 30.10 | Average episode length: 25.15\u001b[0m\n",
      "End of session step 480, Lasted 62.70 s, Best reward: 35.22\n",
      "Still 17642 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 481, Lasted 10.60 s, Best reward: 22.30\n",
      "Still 17500 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 482, Lasted 10.78 s, Best reward: 45.99\n",
      "Still 17496 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 483, Lasted 6.30 s, Best reward: 15.32\n",
      "Still 17481 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 484, Lasted 4.49 s, Best reward: 8.27\n",
      "Still 17473 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 485, Lasted 13.81 s, Best reward: 60.57\n",
      "Still 17333 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 486, Lasted 8.71 s, Best reward: 5.21\n",
      "Still 17210 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 487, Lasted 6.17 s, Best reward: 10.00\n",
      "Still 17167 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 488, Lasted 7.85 s, Best reward: 11.38\n",
      "Still 17140 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 489, Lasted 11.08 s, Best reward: 32.86\n",
      "Still 17044 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 490, Lasted 13.70 s, Best reward: 136.62\n",
      "Still 17031 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 491, Lasted 6.20 s, Best reward: 5.33\n",
      "Still 16903 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 492, Lasted 5.87 s, Best reward: 41.10\n",
      "Still 16878 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 493, Lasted 12.43 s, Best reward: 30.37\n",
      "Still 16737 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 494, Lasted 8.36 s, Best reward: -4.15\n",
      "Still 16680 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 495, Lasted 9.81 s, Best reward: 16.13\n",
      "Still 16578 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 496, Lasted 10.14 s, Best reward: 99.62\n",
      "Still 16561 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 497, Lasted 12.65 s, Best reward: 120.87\n",
      "Still 16499 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 498, Lasted 10.29 s, Best reward: 7.90\n",
      "Still 16411 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 499, Lasted 7.64 s, Best reward: 10.82\n",
      "Still 16364 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 500, Lasted 3.33 s, Best reward: 1.23\n",
      "Still 16352 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 329 | Average return: -1.60 | Average episode length: 8.69\u001b[0m\n",
      "End of session step 501, Lasted 16.98 s, Best reward: 4.44\n",
      "Still 15992 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 502, Lasted 6.68 s, Best reward: 25.07\n",
      "Still 15894 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 319 | Average return: 3.97 | Average episode length: 9.07\u001b[0m\n",
      "End of session step 503, Lasted 18.14 s, Best reward: 49.35\n",
      "Still 15591 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 504, Lasted 4.82 s, Best reward: 6.22\n",
      "Still 15574 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 505, Lasted 4.83 s, Best reward: 12.63\n",
      "Still 15543 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 506, Lasted 3.15 s, Best reward: 3.45\n",
      "Still 15537 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 507, Lasted 7.35 s, Best reward: 2.53\n",
      "Still 15497 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 508, Lasted 11.16 s, Best reward: 63.73\n",
      "Still 15419 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 310 | Average return: 4.19 | Average episode length: 10.35\u001b[0m\n",
      "End of session step 509, Lasted 11.36 s, Best reward: 8.69\n",
      "Still 15208 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 510, Lasted 10.42 s, Best reward: 9.85\n",
      "Still 15105 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 511, Lasted 29.20 s, Best reward: 268.09\n",
      "Still 15010 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 302 | Average return: 5.22 | Average episode length: 11.51\u001b[0m\n",
      "End of session step 512, Lasted 14.85 s, Best reward: 15.30\n",
      "Still 14747 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 513, Lasted 19.28 s, Best reward: 89.03\n",
      "Still 14660 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 514, Lasted 8.64 s, Best reward: 46.79\n",
      "Still 14584 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 515, Lasted 9.76 s, Best reward: 32.39\n",
      "Still 14452 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 516, Lasted 12.32 s, Best reward: 227.06\n",
      "Still 14420 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 290 | Average return: 182.92 | Average episode length: 195.73\u001b[0m\n",
      "End of session step 517, Lasted 208.22 s, Best reward: 478.92\n",
      "Still 14113 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 518, Lasted 6.93 s, Best reward: 20.93\n",
      "Still 14092 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 519, Lasted 9.77 s, Best reward: 2.40\n",
      "Still 14073 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 520, Lasted 31.44 s, Best reward: 5.96\n",
      "Still 13987 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 521, Lasted 51.07 s, Best reward: 5.29\n",
      "Still 13886 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 522, Lasted 21.52 s, Best reward: 22.94\n",
      "Still 13883 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 523, Lasted 68.85 s, Best reward: 107.22\n",
      "Still 13827 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 524, Lasted 16.53 s, Best reward: 14.25\n",
      "Still 13650 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 525, Lasted 43.82 s, Best reward: 1.61\n",
      "Still 13593 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 526, Lasted 87.36 s, Best reward: 209.23\n",
      "Still 13458 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 527, Lasted 40.99 s, Best reward: 6.64\n",
      "Still 13375 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 528, Lasted 8.77 s, Best reward: 3.37\n",
      "Still 13368 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 529, Lasted 35.41 s, Best reward: 98.90\n",
      "Still 13360 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 269 | Average return: 1.52 | Average episode length: 9.49\u001b[0m\n",
      "End of session step 530, Lasted 55.28 s, Best reward: 3.64\n",
      "Still 13132 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 531, Lasted 86.31 s, Best reward: 122.06\n",
      "Still 13060 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 263 | Average return: 4.97 | Average episode length: 8.08\u001b[0m\n",
      "End of session step 532, Lasted 35.51 s, Best reward: 13.17\n",
      "Still 12833 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 533, Lasted 18.78 s, Best reward: 3.31\n",
      "Still 12753 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 534, Lasted 30.71 s, Best reward: 105.78\n",
      "Still 12750 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 535, Lasted 24.01 s, Best reward: 22.75\n",
      "Still 12621 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 254 | Average return: 0.85 | Average episode length: 11.20\u001b[0m\n",
      "End of session step 536, Lasted 17.38 s, Best reward: 11.54\n",
      "Still 12408 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 250 | Average return: 10.73 | Average episode length: 10.57\u001b[0m\n",
      "End of session step 537, Lasted 25.20 s, Best reward: 93.45\n",
      "Still 12257 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 538, Lasted 25.44 s, Best reward: 7.11\n",
      "Still 12198 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 539, Lasted 14.43 s, Best reward: 4.18\n",
      "Still 12142 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 540, Lasted 20.29 s, Best reward: 6.23\n",
      "Still 12037 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 242 | Average return: 57.71 | Average episode length: 56.19\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 484 | Average return: 164.42 | Average episode length: 133.17\u001b[0m\n",
      "End of session step 541, Lasted 507.05 s, Best reward: 322.25\n",
      "Still 11604 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 542, Lasted 50.82 s, Best reward: 64.47\n",
      "Still 11503 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 543, Lasted 33.86 s, Best reward: 87.73\n",
      "Still 11452 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 231 | Average return: -2.20 | Average episode length: 7.59\u001b[0m\n",
      "End of session step 544, Lasted 33.05 s, Best reward: 0.66\n",
      "Still 11229 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 545, Lasted 70.03 s, Best reward: 180.06\n",
      "Still 11164 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 546, Lasted 29.32 s, Best reward: 13.49\n",
      "Still 11091 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 223 | Average return: 2.04 | Average episode length: 18.15\u001b[0m\n",
      "End of session step 547, Lasted 30.78 s, Best reward: 24.60\n",
      "Still 10960 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 548, Lasted 24.88 s, Best reward: 28.30\n",
      "Still 10873 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 549, Lasted 29.92 s, Best reward: 17.10\n",
      "Still 10810 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 550, Lasted 9.10 s, Best reward: 56.20\n",
      "Still 10775 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 551, Lasted 59.84 s, Best reward: 113.35\n",
      "Still 10732 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 216 | Average return: 10.25 | Average episode length: 13.48\u001b[0m\n",
      "End of session step 552, Lasted 46.38 s, Best reward: 35.88\n",
      "Still 10587 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 213 | Average return: 42.21 | Average episode length: 32.82\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 426 | Average return: 135.48 | Average episode length: 91.86\u001b[0m\n",
      "End of session step 553, Lasted 347.81 s, Best reward: 468.90\n",
      "Still 10193 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 554, Lasted 10.39 s, Best reward: 2.24\n",
      "Still 10186 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 555, Lasted 22.40 s, Best reward: 20.99\n",
      "Still 10128 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 556, Lasted 35.49 s, Best reward: 39.44\n",
      "Still 10068 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 557, Lasted 12.95 s, Best reward: 5.08\n",
      "Still 10050 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 558, Lasted 23.50 s, Best reward: 23.07\n",
      "Still 10046 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 202 | Average return: 20.65 | Average episode length: 15.76\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 404 | Average return: 27.84 | Average episode length: 20.52\u001b[0m\n",
      "End of session step 559, Lasted 44.90 s, Best reward: 50.03\n",
      "Still 9723 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 196 | Average return: 0.71 | Average episode length: 11.46\u001b[0m\n",
      "End of session step 560, Lasted 33.15 s, Best reward: 6.78\n",
      "Still 9602 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 194 | Average return: 9.12 | Average episode length: 12.30\u001b[0m\n",
      "End of session step 561, Lasted 16.53 s, Best reward: 57.39\n",
      "Still 9499 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 562, Lasted 12.41 s, Best reward: 62.19\n",
      "Still 9479 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 563, Lasted 20.16 s, Best reward: 4.14\n",
      "Still 9435 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 190 | Average return: 5.14 | Average episode length: 9.77\u001b[0m\n",
      "End of session step 564, Lasted 22.62 s, Best reward: 16.24\n",
      "Still 9282 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 187 | Average return: 48.29 | Average episode length: 36.43\u001b[0m\n",
      "End of session step 565, Lasted 156.59 s, Best reward: 304.92\n",
      "Still 9028 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 182 | Average return: 17.20 | Average episode length: 26.02\u001b[0m\n",
      "End of session step 566, Lasted 82.05 s, Best reward: 141.38\n",
      "Still 8855 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 567, Lasted 10.75 s, Best reward: 78.54\n",
      "Still 8837 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 178 | Average return: 34.27 | Average episode length: 26.80\u001b[0m\n",
      "End of session step 568, Lasted 58.53 s, Best reward: 146.78\n",
      "Still 8739 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 569, Lasted 16.76 s, Best reward: 66.90\n",
      "Still 8724 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 570, Lasted 421.86 s, Best reward: 476.70\n",
      "Still 8664 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 571, Lasted 47.16 s, Best reward: -3.12\n",
      "Still 8589 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 572, Lasted 39.06 s, Best reward: 42.43\n",
      "Still 8573 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 573, Lasted 22.01 s, Best reward: 8.89\n",
      "Still 8538 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 172 | Average return: 12.33 | Average episode length: 14.36\u001b[0m\n",
      "End of session step 574, Lasted 71.57 s, Best reward: 64.34\n",
      "Still 8344 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 575, Lasted 14.41 s, Best reward: 28.56\n",
      "Still 8337 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 168 | Average return: 22.28 | Average episode length: 17.72\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 336 | Average return: 50.49 | Average episode length: 31.57\u001b[0m\n",
      "End of session step 576, Lasted 135.79 s, Best reward: 170.61\n",
      "Still 8089 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 577, Lasted 7.91 s, Best reward: 5.11\n",
      "Still 8087 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 578, Lasted 33.03 s, Best reward: 105.74\n",
      "Still 8064 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 579, Lasted 24.03 s, Best reward: 10.52\n",
      "Still 8012 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 162 | Average return: 4.04 | Average episode length: 7.56\u001b[0m\n",
      "End of session step 580, Lasted 31.73 s, Best reward: 7.83\n",
      "Still 7895 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 159 | Average return: 19.21 | Average episode length: 16.88\u001b[0m\n",
      "End of session step 581, Lasted 66.22 s, Best reward: 48.18\n",
      "Still 7776 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 157 | Average return: 11.43 | Average episode length: 20.85\u001b[0m\n",
      "End of session step 582, Lasted 48.65 s, Best reward: 68.22\n",
      "Still 7619 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 583, Lasted 17.16 s, Best reward: 1.97\n",
      "Still 7577 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 153 | Average return: 4.92 | Average episode length: 8.56\u001b[0m\n",
      "End of session step 584, Lasted 28.50 s, Best reward: 20.66\n",
      "Still 7508 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 585, Lasted 12.32 s, Best reward: 8.12\n",
      "Still 7460 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 151 | Average return: 7.01 | Average episode length: 12.42\u001b[0m\n",
      "End of session step 586, Lasted 22.72 s, Best reward: 17.92\n",
      "Still 7305 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 148 | Average return: 48.82 | Average episode length: 34.31\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 296 | Average return: 78.18 | Average episode length: 50.41\u001b[0m\n",
      "End of session step 587, Lasted 80.04 s, Best reward: 182.72\n",
      "Still 7077 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 143 | Average return: 10.87 | Average episode length: 16.62\u001b[0m\n",
      "End of session step 588, Lasted 24.50 s, Best reward: 46.17\n",
      "Still 6966 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 141 | Average return: 9.63 | Average episode length: 19.77\u001b[0m\n",
      "End of session step 589, Lasted 25.06 s, Best reward: 89.51\n",
      "Still 6850 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 139 | Average return: 3.72 | Average episode length: 16.89\u001b[0m\n",
      "End of session step 590, Lasted 16.45 s, Best reward: 12.37\n",
      "Still 6727 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 591, Lasted 10.03 s, Best reward: 60.99\n",
      "Still 6725 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 592, Lasted 4.55 s, Best reward: -6.40\n",
      "Still 6711 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 136 | Average return: 94.18 | Average episode length: 56.41\u001b[0m\n",
      "End of session step 593, Lasted 18.87 s, Best reward: 251.54\n",
      "Still 6633 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 134 | Average return: 15.72 | Average episode length: 16.53\u001b[0m\n",
      "End of session step 594, Lasted 6.05 s, Best reward: 69.32\n",
      "Still 6593 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 133 | Average return: 2.63 | Average episode length: 10.35\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 266 | Average return: 4.24 | Average episode length: 13.29\u001b[0m\n",
      "End of session step 595, Lasted 9.07 s, Best reward: 50.59\n",
      "Still 6394 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 596, Lasted 6.65 s, Best reward: 2.60\n",
      "Still 6391 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 597, Lasted 5.33 s, Best reward: 53.36\n",
      "Still 6381 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 129 | Average return: 3.48 | Average episode length: 6.74\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 258 | Average return: 3.64 | Average episode length: 6.84\u001b[0m\n",
      "End of session step 598, Lasted 6.31 s, Best reward: 10.31\n",
      "Still 6187 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 125 | Average return: 2.09 | Average episode length: 8.53\u001b[0m\n",
      "End of session step 599, Lasted 7.01 s, Best reward: 12.26\n",
      "Still 6048 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 122 | Average return: 4.42 | Average episode length: 12.77\u001b[0m\n",
      "End of session step 600, Lasted 11.63 s, Best reward: 67.89\n",
      "Still 5905 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 120 | Average return: 1.21 | Average episode length: 6.77\u001b[0m\n",
      "End of session step 601, Lasted 5.32 s, Best reward: 13.50\n",
      "Still 5841 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 602, Lasted 3.47 s, Best reward: 5.48\n",
      "Still 5839 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 603, Lasted 2.29 s, Best reward: 69.38\n",
      "Still 5822 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 118 | Average return: 9.62 | Average episode length: 12.44\u001b[0m\n",
      "End of session step 604, Lasted 1.37 s, Best reward: 49.70\n",
      "Still 5800 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "End of session step 605, Lasted 1.14 s, Best reward: 1.59\n",
      "Still 5798 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 117 | Average return: 10.90 | Average episode length: 11.73\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 234 | Average return: 21.63 | Average episode length: 18.63\u001b[0m\n",
      "End of session step 606, Lasted 3.19 s, Best reward: 65.22\n",
      "Still 5640 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 114 | Average return: 15.16 | Average episode length: 17.22\u001b[0m\n",
      "End of session step 607, Lasted 1.81 s, Best reward: 80.76\n",
      "Still 5613 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 114 | Average return: 4.80 | Average episode length: 8.57\u001b[0m\n",
      "End of session step 608, Lasted 1.28 s, Best reward: 12.50\n",
      "Still 5588 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 113 | Average return: 25.50 | Average episode length: 18.18\u001b[0m\n",
      "End of session step 609, Lasted 4.11 s, Best reward: 93.72\n",
      "Still 5476 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 111 | Average return: 7.60 | Average episode length: 34.38\u001b[0m\n",
      "End of session step 610, Lasted 5.31 s, Best reward: 93.72\n",
      "Still 5428 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 110 | Average return: 48.99 | Average episode length: 39.90\u001b[0m\n",
      "End of session step 611, Lasted 6.10 s, Best reward: 105.57\n",
      "Still 5399 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 109 | Average return: 0.12 | Average episode length: 6.59\u001b[0m\n",
      "End of session step 612, Lasted 1.77 s, Best reward: 1.62\n",
      "Still 5310 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 108 | Average return: 14.47 | Average episode length: 21.47\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 216 | Average return: 23.43 | Average episode length: 27.82\u001b[0m\n",
      "End of session step 613, Lasted 6.60 s, Best reward: 113.76\n",
      "Still 5176 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 105 | Average return: 7.20 | Average episode length: 10.56\u001b[0m\n",
      "End of session step 614, Lasted 1.75 s, Best reward: 32.98\n",
      "Still 5119 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 104 | Average return: 7.78 | Average episode length: 24.79\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 208 | Average return: 6.60 | Average episode length: 21.54\u001b[0m\n",
      "End of session step 615, Lasted 6.89 s, Best reward: 99.68\n",
      "Still 4977 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 101 | Average return: 12.90 | Average episode length: 31.83\u001b[0m\n",
      "End of session step 616, Lasted 3.32 s, Best reward: 67.63\n",
      "Still 4947 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 100 | Average return: 12.67 | Average episode length: 14.82\u001b[0m\n",
      "End of session step 617, Lasted 1.33 s, Best reward: 56.32\n",
      "Still 4940 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 100 | Average return: 0.65 | Average episode length: 8.28\u001b[0m\n",
      "End of session step 618, Lasted 0.99 s, Best reward: 5.23\n",
      "Still 4929 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 100 | Average return: 8.15 | Average episode length: 16.61\u001b[0m\n",
      "End of session step 619, Lasted 1.91 s, Best reward: 27.46\n",
      "Still 4908 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 100 | Average return: 36.94 | Average episode length: 33.12\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 200 | Average return: 70.85 | Average episode length: 53.08\u001b[0m\n",
      "End of session step 620, Lasted 9.79 s, Best reward: 206.89\n",
      "Still 4754 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 97 | Average return: 2.25 | Average episode length: 8.56\u001b[0m\n",
      "End of session step 621, Lasted 1.13 s, Best reward: 8.42\n",
      "Still 4750 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 97 | Average return: 98.13 | Average episode length: 62.12\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 194 | Average return: 101.56 | Average episode length: 63.19\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 291 | Average return: 151.24 | Average episode length: 90.85\u001b[0m\n",
      "End of session step 622, Lasted 19.67 s, Best reward: 347.06\n",
      "Still 4508 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 92 | Average return: -0.72 | Average episode length: 6.85\u001b[0m\n",
      "End of session step 623, Lasted 0.78 s, Best reward: 0.38\n",
      "Still 4479 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 91 | Average return: 12.43 | Average episode length: 15.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 182 | Average return: 9.73 | Average episode length: 12.65\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 273 | Average return: 15.78 | Average episode length: 15.93\u001b[0m\n",
      "End of session step 624, Lasted 3.53 s, Best reward: 43.73\n",
      "Still 4263 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 87 | Average return: 46.20 | Average episode length: 33.75\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 174 | Average return: 67.75 | Average episode length: 43.83\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 261 | Average return: 88.45 | Average episode length: 52.97\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 348 | Average return: 129.06 | Average episode length: 70.77\u001b[0m\n",
      "End of session step 625, Lasted 16.32 s, Best reward: 261.27\n",
      "Still 3934 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 80 | Average return: 7.85 | Average episode length: 31.60\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 160 | Average return: 18.20 | Average episode length: 40.10\u001b[0m\n",
      "End of session step 626, Lasted 5.22 s, Best reward: 149.68\n",
      "Still 3836 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 78 | Average return: 7.54 | Average episode length: 10.16\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 156 | Average return: 6.52 | Average episode length: 9.90\u001b[0m\n",
      "End of session step 627, Lasted 1.58 s, Best reward: 15.82\n",
      "Still 3740 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 76 | Average return: 4.41 | Average episode length: 13.82\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 152 | Average return: 5.56 | Average episode length: 17.78\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 228 | Average return: 8.04 | Average episode length: 21.03\u001b[0m\n",
      "End of session step 628, Lasted 3.74 s, Best reward: 37.44\n",
      "Still 3559 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 73 | Average return: 31.76 | Average episode length: 29.76\u001b[0m\n",
      "End of session step 629, Lasted 2.80 s, Best reward: 96.03\n",
      "Still 3543 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 72 | Average return: 4.03 | Average episode length: 11.81\u001b[0m\n",
      "End of session step 630, Lasted 1.00 s, Best reward: 6.55\n",
      "Still 3533 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 72 | Average return: 14.21 | Average episode length: 14.75\u001b[0m\n",
      "End of session step 631, Lasted 1.60 s, Best reward: 46.34\n",
      "Still 3512 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 72 | Average return: 5.61 | Average episode length: 15.48\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 144 | Average return: 13.38 | Average episode length: 17.92\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 216 | Average return: 23.36 | Average episode length: 22.44\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 288 | Average return: 28.08 | Average episode length: 26.01\u001b[0m\n",
      "End of session step 632, Lasted 5.00 s, Best reward: 124.07\n",
      "Still 3283 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 67 | Average return: 0.11 | Average episode length: 10.56\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 134 | Average return: -0.07 | Average episode length: 10.09\u001b[0m\n",
      "End of session step 633, Lasted 1.32 s, Best reward: 2.64\n",
      "Still 3229 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 66 | Average return: 0.82 | Average episode length: 9.04\u001b[0m\n",
      "End of session step 634, Lasted 0.81 s, Best reward: 3.03\n",
      "Still 3221 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 66 | Average return: 5.35 | Average episode length: 8.33\u001b[0m\n",
      "End of session step 635, Lasted 0.77 s, Best reward: 7.80\n",
      "Still 3208 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 66 | Average return: 6.98 | Average episode length: 12.12\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 132 | Average return: 6.92 | Average episode length: 11.29\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 198 | Average return: 6.96 | Average episode length: 10.94\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 264 | Average return: 11.65 | Average episode length: 14.48\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 330 | Average return: 11.67 | Average episode length: 14.50\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 396 | Average return: 15.32 | Average episode length: 16.52\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 462 | Average return: 16.20 | Average episode length: 17.06\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 528 | Average return: 12.54 | Average episode length: 15.58\u001b[0m\n",
      "End of session step 636, Lasted 6.04 s, Best reward: 25.25\n",
      "Still 2777 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 57 | Average return: 0.82 | Average episode length: 27.16\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 114 | Average return: 1.57 | Average episode length: 25.91\u001b[0m\n",
      "End of session step 637, Lasted 3.29 s, Best reward: 8.46\n",
      "Still 2711 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 56 | Average return: 13.78 | Average episode length: 14.98\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 112 | Average return: 10.91 | Average episode length: 12.61\u001b[0m\n",
      "End of session step 638, Lasted 1.29 s, Best reward: 32.96\n",
      "Still 2695 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 55 | Average return: -0.78 | Average episode length: 9.96\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 110 | Average return: 0.67 | Average episode length: 10.36\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 165 | Average return: 0.07 | Average episode length: 9.42\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 220 | Average return: 0.24 | Average episode length: 10.62\u001b[0m\n",
      "End of session step 639, Lasted 1.94 s, Best reward: 9.15\n",
      "Still 2569 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 53 | Average return: 36.30 | Average episode length: 25.17\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 106 | Average return: 49.43 | Average episode length: 32.55\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 159 | Average return: 46.93 | Average episode length: 30.62\u001b[0m\n",
      "End of session step 640, Lasted 3.60 s, Best reward: 136.07\n",
      "Still 2498 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 51 | Average return: 1.98 | Average episode length: 10.94\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 102 | Average return: 1.34 | Average episode length: 10.67\u001b[0m\n",
      "End of session step 641, Lasted 1.19 s, Best reward: 7.14\n",
      "Still 2468 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 51 | Average return: 5.31 | Average episode length: 10.21\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 102 | Average return: 5.56 | Average episode length: 10.76\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 153 | Average return: 5.67 | Average episode length: 14.29\u001b[0m\n",
      "End of session step 642, Lasted 1.85 s, Best reward: 9.43\n",
      "Still 2385 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 49 | Average return: 1.74 | Average episode length: 10.68\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 98 | Average return: 0.96 | Average episode length: 10.82\u001b[0m\n",
      "End of session step 643, Lasted 2.04 s, Best reward: 6.18\n",
      "Still 2358 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 49 | Average return: 23.64 | Average episode length: 20.78\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 98 | Average return: 26.23 | Average episode length: 23.80\u001b[0m\n",
      "End of session step 644, Lasted 1.78 s, Best reward: 82.03\n",
      "Still 2356 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 49 | Average return: 49.18 | Average episode length: 48.52\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 98 | Average return: 87.81 | Average episode length: 65.29\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 147 | Average return: 117.02 | Average episode length: 74.55\u001b[0m\n",
      "End of session step 645, Lasted 9.09 s, Best reward: 260.29\n",
      "Still 2264 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 47 | Average return: 5.52 | Average episode length: 9.12\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 94 | Average return: 16.36 | Average episode length: 17.04\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 141 | Average return: 30.95 | Average episode length: 25.40\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 188 | Average return: 57.62 | Average episode length: 37.23\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 235 | Average return: 67.86 | Average episode length: 41.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 282 | Average return: 73.37 | Average episode length: 44.43\u001b[0m\n",
      "End of session step 646, Lasted 8.34 s, Best reward: 159.55\n",
      "Still 2058 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 43 | Average return: -2.57 | Average episode length: 10.66\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 86 | Average return: -1.49 | Average episode length: 10.44\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 129 | Average return: -3.70 | Average episode length: 10.30\u001b[0m\n",
      "End of session step 647, Lasted 1.30 s, Best reward: 13.55\n",
      "Still 2024 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 42 | Average return: -0.63 | Average episode length: 6.02\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 84 | Average return: -0.55 | Average episode length: 6.00\u001b[0m\n",
      "End of session step 648, Lasted 0.70 s, Best reward: 0.91\n",
      "Still 2020 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 42 | Average return: 37.23 | Average episode length: 31.86\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 84 | Average return: 31.99 | Average episode length: 29.81\u001b[0m\n",
      "End of session step 649, Lasted 3.05 s, Best reward: 146.09\n",
      "Still 2011 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 42 | Average return: -0.62 | Average episode length: 6.05\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 84 | Average return: -0.94 | Average episode length: 6.14\u001b[0m\n",
      "End of session step 650, Lasted 1.01 s, Best reward: 0.27\n",
      "Still 1994 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 41 | Average return: 3.19 | Average episode length: 7.88\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 82 | Average return: 3.83 | Average episode length: 8.90\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 123 | Average return: 3.56 | Average episode length: 8.39\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 164 | Average return: 3.40 | Average episode length: 8.39\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 205 | Average return: 5.20 | Average episode length: 10.05\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 246 | Average return: 4.24 | Average episode length: 8.93\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 287 | Average return: 5.49 | Average episode length: 10.41\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 328 | Average return: 3.88 | Average episode length: 8.41\u001b[0m\n",
      "End of session step 651, Lasted 3.61 s, Best reward: 18.06\n",
      "Still 1760 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 37 | Average return: 5.17 | Average episode length: 9.13\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 74 | Average return: 5.31 | Average episode length: 9.35\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 111 | Average return: 5.16 | Average episode length: 9.46\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 148 | Average return: 5.73 | Average episode length: 9.78\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 185 | Average return: 4.92 | Average episode length: 9.46\u001b[0m\n",
      "End of session step 652, Lasted 7.81 s, Best reward: 15.88\n",
      "Still 1642 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 34 | Average return: 127.45 | Average episode length: 135.20\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 68 | Average return: 99.68 | Average episode length: 89.32\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 102 | Average return: 176.68 | Average episode length: 161.21\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 136 | Average return: 118.33 | Average episode length: 95.79\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 170 | Average return: 76.51 | Average episode length: 64.85\u001b[0m\n",
      "End of session step 653, Lasted 58.32 s, Best reward: 384.40\n",
      "Still 1539 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 32 | Average return: 4.70 | Average episode length: 10.24\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 64 | Average return: 3.62 | Average episode length: 7.97\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 96 | Average return: 3.59 | Average episode length: 8.00\u001b[0m\n",
      "End of session step 654, Lasted 2.88 s, Best reward: 10.70\n",
      "Still 1532 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 32 | Average return: -5.48 | Average episode length: 17.70\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 64 | Average return: -3.08 | Average episode length: 16.97\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 96 | Average return: -1.50 | Average episode length: 17.34\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 128 | Average return: -2.49 | Average episode length: 16.94\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 160 | Average return: -0.74 | Average episode length: 15.72\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 192 | Average return: -1.31 | Average episode length: 15.50\u001b[0m\n",
      "End of session step 655, Lasted 11.55 s, Best reward: 15.22\n",
      "Still 1436 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 30 | Average return: 0.63 | Average episode length: 8.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 60 | Average return: 0.48 | Average episode length: 7.93\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 90 | Average return: 0.48 | Average episode length: 10.27\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 120 | Average return: 0.07 | Average episode length: 13.60\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 150 | Average return: 0.94 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 180 | Average return: 1.25 | Average episode length: 9.87\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 210 | Average return: 1.34 | Average episode length: 9.63\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 240 | Average return: 1.04 | Average episode length: 9.70\u001b[0m\n",
      "End of session step 656, Lasted 9.02 s, Best reward: 7.88\n",
      "Still 1275 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 27 | Average return: -0.45 | Average episode length: 6.46\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 54 | Average return: 1.17 | Average episode length: 7.41\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 81 | Average return: 1.43 | Average episode length: 7.67\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 108 | Average return: 0.75 | Average episode length: 7.04\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 135 | Average return: 1.63 | Average episode length: 7.93\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 162 | Average return: 0.75 | Average episode length: 7.44\u001b[0m\n",
      "End of session step 657, Lasted 4.48 s, Best reward: 4.18\n",
      "Still 1189 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 25 | Average return: 8.11 | Average episode length: 15.73\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 50 | Average return: 8.02 | Average episode length: 13.52\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 75 | Average return: 7.11 | Average episode length: 16.28\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 100 | Average return: 8.20 | Average episode length: 14.84\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 125 | Average return: 10.66 | Average episode length: 17.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 150 | Average return: 8.24 | Average episode length: 14.96\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 175 | Average return: 12.53 | Average episode length: 17.68\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 200 | Average return: 7.08 | Average episode length: 13.08\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 225 | Average return: 6.42 | Average episode length: 12.92\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 250 | Average return: 5.41 | Average episode length: 12.04\u001b[0m\n",
      "End of session step 658, Lasted 10.31 s, Best reward: 59.22\n",
      "Still 1028 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 22 | Average return: 2.51 | Average episode length: 11.87\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 44 | Average return: 2.07 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 66 | Average return: 2.51 | Average episode length: 13.27\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 88 | Average return: 2.64 | Average episode length: 12.36\u001b[0m\n",
      "End of session step 659, Lasted 3.16 s, Best reward: 8.59\n",
      "Still 1023 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 22 | Average return: 4.45 | Average episode length: 9.39\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 44 | Average return: 7.72 | Average episode length: 11.55\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 66 | Average return: 9.91 | Average episode length: 13.45\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 88 | Average return: 13.54 | Average episode length: 15.64\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 110 | Average return: 8.92 | Average episode length: 13.59\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 132 | Average return: 7.08 | Average episode length: 12.45\u001b[0m\n",
      "End of session step 660, Lasted 4.11 s, Best reward: 53.39\n",
      "Still 990 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 21 | Average return: 2.42 | Average episode length: 6.18\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 42 | Average return: 2.37 | Average episode length: 6.24\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 63 | Average return: 2.36 | Average episode length: 6.29\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 84 | Average return: 2.39 | Average episode length: 6.24\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 105 | Average return: 2.39 | Average episode length: 6.24\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 126 | Average return: 2.34 | Average episode length: 6.10\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 147 | Average return: 2.27 | Average episode length: 6.14\u001b[0m\n",
      "End of session step 661, Lasted 4.34 s, Best reward: 3.10\n",
      "Still 924 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 20 | Average return: 36.82 | Average episode length: 41.14\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: 24.24 | Average episode length: 31.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: 30.56 | Average episode length: 37.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: 30.40 | Average episode length: 36.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 100 | Average return: 30.65 | Average episode length: 35.75\u001b[0m\n",
      "End of session step 662, Lasted 8.60 s, Best reward: 230.82\n",
      "Still 909 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 20 | Average return: 18.53 | Average episode length: 27.43\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: 15.67 | Average episode length: 25.85\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: 20.02 | Average episode length: 29.45\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: 14.06 | Average episode length: 19.90\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 100 | Average return: 18.55 | Average episode length: 23.10\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 120 | Average return: 15.30 | Average episode length: 21.80\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 140 | Average return: 16.82 | Average episode length: 24.05\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 160 | Average return: 13.26 | Average episode length: 19.70\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 180 | Average return: 11.83 | Average episode length: 17.55\u001b[0m\n",
      "End of session step 663, Lasted 11.12 s, Best reward: 63.74\n",
      "Still 810 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 18 | Average return: 5.57 | Average episode length: 15.89\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 36 | Average return: 6.83 | Average episode length: 16.33\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 54 | Average return: 5.99 | Average episode length: 16.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 72 | Average return: 5.15 | Average episode length: 15.83\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 90 | Average return: 5.48 | Average episode length: 15.28\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 108 | Average return: 4.23 | Average episode length: 15.61\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 126 | Average return: 3.11 | Average episode length: 13.61\u001b[0m\n",
      "End of session step 664, Lasted 6.55 s, Best reward: 19.36\n",
      "Still 774 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 17 | Average return: 13.08 | Average episode length: 13.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 34 | Average return: 7.56 | Average episode length: 9.76\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 51 | Average return: 9.88 | Average episode length: 13.06\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 68 | Average return: 24.08 | Average episode length: 22.29\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 85 | Average return: 30.45 | Average episode length: 24.65\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 102 | Average return: 34.82 | Average episode length: 25.82\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 119 | Average return: 40.50 | Average episode length: 32.71\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 136 | Average return: 41.67 | Average episode length: 32.12\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 153 | Average return: 52.62 | Average episode length: 37.53\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 170 | Average return: 49.24 | Average episode length: 34.35\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 187 | Average return: 53.81 | Average episode length: 35.65\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 204 | Average return: 44.72 | Average episode length: 29.71\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 221 | Average return: 51.94 | Average episode length: 33.76\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 238 | Average return: 61.18 | Average episode length: 38.59\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 255 | Average return: 74.65 | Average episode length: 45.12\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 272 | Average return: 91.68 | Average episode length: 52.94\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 289 | Average return: 120.58 | Average episode length: 66.82\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 306 | Average return: 79.77 | Average episode length: 45.76\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 323 | Average return: 103.60 | Average episode length: 57.24\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 340 | Average return: 85.40 | Average episode length: 50.29\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 357 | Average return: 88.98 | Average episode length: 49.41\u001b[0m\n",
      "End of session step 665, Lasted 28.86 s, Best reward: 258.20\n",
      "Still 510 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 12 | Average return: 3.32 | Average episode length: 7.92\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 24 | Average return: 5.52 | Average episode length: 8.50\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 36 | Average return: 6.47 | Average episode length: 9.17\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 48 | Average return: 6.34 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: 7.59 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 72 | Average return: 9.28 | Average episode length: 10.08\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 84 | Average return: 8.83 | Average episode length: 9.67\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 96 | Average return: 8.56 | Average episode length: 9.42\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 108 | Average return: 8.29 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 120 | Average return: 7.57 | Average episode length: 9.33\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 132 | Average return: 8.15 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 144 | Average return: 8.06 | Average episode length: 9.17\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 156 | Average return: 8.35 | Average episode length: 9.67\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 168 | Average return: 8.39 | Average episode length: 9.33\u001b[0m\n",
      "End of session step 666, Lasted 5.13 s, Best reward: 13.64\n",
      "Still 436 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 10 | Average return: 16.73 | Average episode length: 14.36\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 20 | Average return: 21.80 | Average episode length: 16.20\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 30 | Average return: 22.16 | Average episode length: 16.90\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 40 | Average return: 15.17 | Average episode length: 16.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 50 | Average return: 14.00 | Average episode length: 13.10\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: 21.64 | Average episode length: 17.10\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 70 | Average return: 13.56 | Average episode length: 12.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: 10.52 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 90 | Average return: 20.07 | Average episode length: 15.30\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 100 | Average return: 13.91 | Average episode length: 13.30\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 110 | Average return: 16.40 | Average episode length: 13.70\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 120 | Average return: 33.84 | Average episode length: 21.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 130 | Average return: 18.04 | Average episode length: 15.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 140 | Average return: 23.51 | Average episode length: 16.90\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 150 | Average return: 33.85 | Average episode length: 21.30\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 160 | Average return: 31.39 | Average episode length: 21.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 170 | Average return: 29.02 | Average episode length: 19.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 180 | Average return: 28.34 | Average episode length: 18.60\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 190 | Average return: 34.56 | Average episode length: 22.80\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 200 | Average return: 20.83 | Average episode length: 15.90\u001b[0m\n",
      "End of session step 667, Lasted 9.19 s, Best reward: 56.58\n",
      "Still 334 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 8 | Average return: 2.15 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 16 | Average return: 2.29 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 24 | Average return: 2.28 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 32 | Average return: 2.29 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: 1.81 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 48 | Average return: 1.81 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 56 | Average return: 1.65 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 64 | Average return: 1.66 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 72 | Average return: 1.79 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 80 | Average return: 1.89 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 88 | Average return: 2.24 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 96 | Average return: 2.59 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 104 | Average return: 2.86 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 112 | Average return: 2.76 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 120 | Average return: 2.59 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 128 | Average return: 2.75 | Average episode length: 7.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 136 | Average return: 8.07 | Average episode length: 10.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 144 | Average return: 9.90 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 152 | Average return: 22.44 | Average episode length: 18.62\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 160 | Average return: 32.06 | Average episode length: 22.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 168 | Average return: 33.43 | Average episode length: 24.12\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 176 | Average return: 39.19 | Average episode length: 26.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 184 | Average return: 36.41 | Average episode length: 25.62\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 192 | Average return: 28.81 | Average episode length: 21.62\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 200 | Average return: 30.47 | Average episode length: 23.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 208 | Average return: 29.66 | Average episode length: 23.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 216 | Average return: 27.39 | Average episode length: 21.88\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 224 | Average return: 32.18 | Average episode length: 24.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 232 | Average return: 32.56 | Average episode length: 24.62\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 240 | Average return: 30.84 | Average episode length: 24.12\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 248 | Average return: 31.75 | Average episode length: 24.88\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 256 | Average return: 35.85 | Average episode length: 27.00\u001b[0m\n",
      "End of session step 668, Lasted 13.86 s, Best reward: 49.66\n",
      "Still 176 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 5 | Average return: -0.23 | Average episode length: 14.83\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 10 | Average return: -0.39 | Average episode length: 20.80\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 15 | Average return: 0.04 | Average episode length: 18.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 20 | Average return: -1.22 | Average episode length: 17.40\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 25 | Average return: -0.80 | Average episode length: 13.80\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 30 | Average return: 0.04 | Average episode length: 18.40\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 35 | Average return: -0.91 | Average episode length: 19.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: -1.30 | Average episode length: 16.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 45 | Average return: -2.21 | Average episode length: 19.40\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 50 | Average return: -1.67 | Average episode length: 15.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 55 | Average return: -1.86 | Average episode length: 15.80\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: -0.35 | Average episode length: 19.40\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 65 | Average return: -2.29 | Average episode length: 16.80\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 70 | Average return: -1.76 | Average episode length: 15.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 75 | Average return: -2.17 | Average episode length: 12.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: -2.87 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 85 | Average return: -3.45 | Average episode length: 9.40\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 90 | Average return: -3.14 | Average episode length: 9.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 95 | Average return: -3.29 | Average episode length: 9.20\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 100 | Average return: -2.81 | Average episode length: 9.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 105 | Average return: -2.83 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 110 | Average return: -3.23 | Average episode length: 9.00\u001b[0m\n",
      "End of session step 669, Lasted 7.10 s, Best reward: 4.11\n",
      "Still 162 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 5 | Average return: 91.05 | Average episode length: 81.17\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 10 | Average return: 95.62 | Average episode length: 87.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 15 | Average return: 74.08 | Average episode length: 54.20\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 20 | Average return: 141.28 | Average episode length: 135.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 25 | Average return: 80.55 | Average episode length: 83.80\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 30 | Average return: 101.04 | Average episode length: 93.60\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 35 | Average return: 124.00 | Average episode length: 123.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 40 | Average return: 130.32 | Average episode length: 108.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 45 | Average return: 136.80 | Average episode length: 98.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 50 | Average return: 178.56 | Average episode length: 130.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 55 | Average return: 113.91 | Average episode length: 104.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 60 | Average return: 100.10 | Average episode length: 85.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 65 | Average return: 36.13 | Average episode length: 37.20\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 70 | Average return: 101.41 | Average episode length: 80.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 75 | Average return: 104.10 | Average episode length: 86.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: 91.34 | Average episode length: 82.80\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 85 | Average return: 110.43 | Average episode length: 98.20\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 90 | Average return: 204.71 | Average episode length: 138.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 95 | Average return: 93.41 | Average episode length: 71.60\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 100 | Average return: 131.65 | Average episode length: 99.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 105 | Average return: 130.24 | Average episode length: 111.40\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 110 | Average return: 111.56 | Average episode length: 87.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 115 | Average return: 125.99 | Average episode length: 97.60\u001b[0m\n",
      "End of session step 670, Lasted 27.50 s, Best reward: 416.54\n",
      "Still 142 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 4 | Average return: -0.56 | Average episode length: 14.60\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 8 | Average return: -2.07 | Average episode length: 10.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 12 | Average return: -3.33 | Average episode length: 11.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 16 | Average return: -1.73 | Average episode length: 11.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 20 | Average return: -2.42 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 24 | Average return: -2.22 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 28 | Average return: -1.65 | Average episode length: 11.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 32 | Average return: -2.29 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 36 | Average return: -2.06 | Average episode length: 12.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: -2.44 | Average episode length: 12.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 44 | Average return: -2.12 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 48 | Average return: -2.50 | Average episode length: 13.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 52 | Average return: -2.25 | Average episode length: 12.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 56 | Average return: -3.03 | Average episode length: 12.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: -2.61 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 64 | Average return: -3.54 | Average episode length: 11.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 68 | Average return: -1.72 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 72 | Average return: -2.81 | Average episode length: 11.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 76 | Average return: -2.69 | Average episode length: 14.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: -4.21 | Average episode length: 10.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 84 | Average return: -2.89 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 88 | Average return: -3.75 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 92 | Average return: -2.96 | Average episode length: 12.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 96 | Average return: -1.77 | Average episode length: 13.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 100 | Average return: -3.82 | Average episode length: 11.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 104 | Average return: -2.03 | Average episode length: 11.50\u001b[0m\n",
      "End of session step 671, Lasted 3.89 s, Best reward: 2.41\n",
      "Still 136 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 4 | Average return: 2.49 | Average episode length: 9.20\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 8 | Average return: 2.19 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 12 | Average return: 1.91 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 16 | Average return: 2.02 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 20 | Average return: 1.97 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 24 | Average return: 1.81 | Average episode length: 10.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 28 | Average return: 1.94 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 32 | Average return: 1.71 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 36 | Average return: 1.97 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 40 | Average return: 2.04 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 44 | Average return: 1.88 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 48 | Average return: 1.86 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 52 | Average return: 1.60 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 56 | Average return: 1.58 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: 1.88 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 64 | Average return: 1.90 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 68 | Average return: 1.82 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 72 | Average return: 2.17 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 76 | Average return: 1.92 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: 1.89 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 84 | Average return: 1.81 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 88 | Average return: 1.56 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 92 | Average return: 1.45 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 96 | Average return: 1.29 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 100 | Average return: 1.14 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 104 | Average return: 1.29 | Average episode length: 9.25\u001b[0m\n",
      "End of session step 672, Lasted 3.23 s, Best reward: 2.90\n",
      "Still 131 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 4 | Average return: 2.64 | Average episode length: 8.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 8 | Average return: 3.18 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 12 | Average return: 1.74 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 16 | Average return: 3.20 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 20 | Average return: 3.06 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 24 | Average return: 24.11 | Average episode length: 20.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 28 | Average return: 2.59 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 32 | Average return: 4.74 | Average episode length: 10.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 36 | Average return: 4.00 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: 3.35 | Average episode length: 8.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 44 | Average return: 1.59 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 48 | Average return: 2.50 | Average episode length: 9.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 52 | Average return: 2.77 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 56 | Average return: 4.13 | Average episode length: 8.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 60 | Average return: 2.39 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 64 | Average return: 1.62 | Average episode length: 7.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 68 | Average return: 2.80 | Average episode length: 9.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 72 | Average return: 2.45 | Average episode length: 8.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 76 | Average return: 2.27 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 80 | Average return: 1.67 | Average episode length: 7.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 84 | Average return: 2.78 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 88 | Average return: 2.98 | Average episode length: 8.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 92 | Average return: 4.00 | Average episode length: 8.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 96 | Average return: 6.07 | Average episode length: 11.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 100 | Average return: 2.76 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 104 | Average return: 5.68 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 108 | Average return: 3.31 | Average episode length: 8.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 112 | Average return: 2.13 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 116 | Average return: 4.37 | Average episode length: 10.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 120 | Average return: 5.20 | Average episode length: 11.25\u001b[0m\n",
      "End of session step 673, Lasted 3.70 s, Best reward: 50.45\n",
      "Still 107 to go\n",
      "Successful loading of the reinforce with baseline agent.\n",
      "\u001b[1;32;40mEpisode: 4 | Average return: 1.32 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 8 | Average return: 0.57 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 12 | Average return: 0.83 | Average episode length: 8.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 16 | Average return: 1.08 | Average episode length: 8.00\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 20 | Average return: 3.13 | Average episode length: 15.25\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 24 | Average return: 4.91 | Average episode length: 14.25\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 28 | Average return: 0.91 | Average episode length: 7.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 32 | Average return: 1.40 | Average episode length: 9.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 36 | Average return: 4.95 | Average episode length: 16.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 40 | Average return: 0.86 | Average episode length: 7.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 44 | Average return: 1.88 | Average episode length: 11.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 48 | Average return: 2.08 | Average episode length: 13.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 52 | Average return: 1.65 | Average episode length: 10.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 56 | Average return: 0.67 | Average episode length: 10.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 60 | Average return: 1.25 | Average episode length: 10.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 64 | Average return: 2.00 | Average episode length: 13.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 68 | Average return: 0.98 | Average episode length: 11.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 72 | Average return: 2.03 | Average episode length: 11.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 76 | Average return: 1.66 | Average episode length: 12.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 80 | Average return: 2.05 | Average episode length: 12.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 84 | Average return: 2.64 | Average episode length: 13.50\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 88 | Average return: 8.30 | Average episode length: 27.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 92 | Average return: 0.98 | Average episode length: 10.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 96 | Average return: 0.44 | Average episode length: 9.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 100 | Average return: 2.37 | Average episode length: 12.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 104 | Average return: 3.66 | Average episode length: 15.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 108 | Average return: 4.47 | Average episode length: 15.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 112 | Average return: 5.26 | Average episode length: 18.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 116 | Average return: 2.37 | Average episode length: 13.25\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 120 | Average return: 8.13 | Average episode length: 19.25\u001b[0m\n",
      "\u001b[1;32;40mEpisode: 124 | Average return: 13.95 | Average episode length: 26.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 128 | Average return: 8.66 | Average episode length: 18.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 132 | Average return: 2.09 | Average episode length: 13.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 136 | Average return: 7.87 | Average episode length: 22.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 140 | Average return: 9.95 | Average episode length: 24.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 144 | Average return: 1.02 | Average episode length: 12.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 148 | Average return: 1.87 | Average episode length: 13.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 152 | Average return: 2.29 | Average episode length: 12.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 156 | Average return: 2.80 | Average episode length: 16.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 160 | Average return: 2.35 | Average episode length: 14.50\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 164 | Average return: 1.08 | Average episode length: 10.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 168 | Average return: 2.22 | Average episode length: 12.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 172 | Average return: 0.59 | Average episode length: 10.75\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 176 | Average return: 2.62 | Average episode length: 12.75\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 180 | Average return: 1.01 | Average episode length: 13.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 184 | Average return: 1.65 | Average episode length: 13.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 188 | Average return: 2.85 | Average episode length: 16.00\u001b[0m\n",
      "\u001b[1;31;40mEpisode: 192 | Average return: 0.43 | Average episode length: 10.25\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 196 | Average return: 1.69 | Average episode length: 12.50\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 200 | Average return: 2.17 | Average episode length: 14.00\u001b[0m\n",
      "\u001b[1;33;40mEpisode: 204 | Average return: 5.45 | Average episode length: 17.25\u001b[0m\n",
      "End of session step 674, Lasted 9.92 s, Best reward: 38.69\n",
      "Still 0 to go\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"outputs/rein-es20k100\"\n",
    "session = Session(SOURCE_ENV, output_folder, verbose=10)\n",
    "session.load_last_reinforce(baseline=50)\n",
    "step = session.get_step()\n",
    "session.store_infos(f\"Step {step}: Reinforce, 20k episodes, early stopping=100, 10k trials\")\n",
    "session.train_agent_with_early_stopping(20000, 100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful loading of the actor-critic agent.\n",
      "Episode: 0 | Return: 2.12\n",
      "Episode: 1 | Return: 1.93\n",
      "Episode: 2 | Return: 2.17\n",
      "Episode: 3 | Return: 2.08\n",
      "Episode: 4 | Return: 2.24\n",
      "Episode: 5 | Return: 2.07\n",
      "Episode: 6 | Return: 2.25\n",
      "Episode: 7 | Return: 2.23\n",
      "Episode: 8 | Return: 1.91\n",
      "Episode: 9 | Return: 2.10\n",
      "Average reward: 2.11 | Average episode Length: 0.00 | Maximum train reward: 2.25\n",
      "End of session step 685, lasted 0.16 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "session.load_actor_critic(\n",
    "    \"outputs/ac-es20k20/step_800_train/best_model.mdl\", \"outputs/ac-es20k20/step_390_train/best_critic.mdl\")\n",
    "session.test_agent(render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_foler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/basic_ac2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m session \u001b[38;5;241m=\u001b[39m Session(SOURCE_ENV, \u001b[43moutput_folder\u001b[49m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m session\u001b[38;5;241m.\u001b[39mload_actor_critic()\n\u001b[1;32m      4\u001b[0m session\u001b[38;5;241m.\u001b[39mtrain_agent(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_folder' is not defined"
     ]
    }
   ],
   "source": [
    "output_foler = \"outputs/basic_ac2\"\n",
    "session = Session(SOURCE_ENV, output_folder, 5)\n",
    "session.load_actor_critic()\n",
    "session.train_agent(10000, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MESA: error: ZINK: failed to choose pdev\n",
      "glx: failed to create drisw screen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 | Return: 47.98\n",
      "Episode: 1 | Return: 47.85\n",
      "Episode: 2 | Return: 41.37\n",
      "Episode: 3 | Return: 48.50\n",
      "Episode: 4 | Return: 47.02\n",
      "Episode: 5 | Return: 53.79\n",
      "Episode: 6 | Return: -1.76\n",
      "Episode: 7 | Return: 46.13\n",
      "Episode: 8 | Return: 49.64\n",
      "Episode: 9 | Return: 49.05\n",
      "Average reward: 42.96 | Average episode Length: 0.00 | Maximum train reward: 53.79\n",
      "End of session step 687, lasted 2.32 s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "session.test_agent(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
